{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "This notebook shows how to apply transfer learning on image datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:34:47.416060Z",
     "start_time": "2019-03-13T13:34:45.812050Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the data location and the place to save the model\n",
    "\n",
    "Unfortunately the data used here is a private data. However it can be replaced by any healthy/unhealthy classification problem as long as the folder structure is followed.\n",
    "\n",
    "*   training\n",
    "    *   healthy\n",
    "    *   unhealthy    \n",
    "*   test    \n",
    "    *   healthy\n",
    "    *   unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:42:00.019264Z",
     "start_time": "2019-03-13T13:42:00.016388Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '~/datasets/rice/train/'\n",
    "TEST_DIR = '~/datasets/rice/test/'\n",
    "CKPT_DIR='vgg_16_ckpts_{epoch:03d}.ckpt'\n",
    "BEST_DIR='vgg_16_best.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the images and add augmentations\n",
    "\n",
    "The training/validation set has multiple random data transformations while the training set is just scaled for the sake of normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:42:01.042333Z",
     "start_time": "2019-03-13T13:42:00.713058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images belonging to 2 classes.\n",
      "Found 8 images belonging to 2 classes.\n",
      "Found 22 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_idg = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=360,\n",
    "    zoom_range=0.5,\n",
    "    fill_mode='reflect',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2,\n",
    "    rescale=1.0/255\n",
    ")\n",
    "test_idg = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "class_mode = 'binary'\n",
    "classes = {\n",
    "    'healthy': 0,\n",
    "    'unhealthy': 1,\n",
    "}\n",
    "\n",
    "train_gen = train_idg.flow_from_directory(TRAIN_DIR, (224, 224),\n",
    "                                          seed=0,\n",
    "                                          batch_size=128,\n",
    "                                          subset='training',\n",
    "                                          class_mode=class_mode,\n",
    "                                          classes=classes)\n",
    "\n",
    "valid_gen = train_idg.flow_from_directory(TRAIN_DIR, (224, 224),\n",
    "                                          seed=0,\n",
    "                                          batch_size=128,\n",
    "                                          subset='validation',\n",
    "                                          class_mode=class_mode,    \n",
    "                                          classes=classes)\n",
    "\n",
    "test_gen = test_idg.flow_from_directory(TEST_DIR, (224, 224),\n",
    "                                        class_mode=class_mode,\n",
    "                                        classes=classes,\n",
    "                                        shuffle=False,\n",
    "                                        batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a base model and add additional layers\n",
    "\n",
    "Load the keras VGG model without the last/top layers and add the needed layers to solve the classification problem. Also some of the initial layers of the VGG model are set to be not trainable since only fine tuning is done to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-10T13:32:54.349Z"
    }
   },
   "outputs": [],
   "source": [
    "img_input = tf.keras.layers.Input((224, 224, 3))\n",
    "base_model = tf.keras.applications.VGG16(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=img_input)\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=img_input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile('adam', 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Keras model\n",
    "\n",
    "Different callbacks are also added save the model and regularize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-10T13:32:54.357Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps, validate for 1 steps\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\users\\snowt\\.conda\\envs\\machine-learning\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_001.ckpt\\assets\n",
      "INFO:tensorflow:Assets written to: vgg_16_best.ckpt\\assets\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.6876 - val_loss: 1.4342\n",
      "Epoch 2/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_002.ckpt\\assets\n",
      "INFO:tensorflow:Assets written to: vgg_16_best.ckpt\\assets\n",
      "1/1 [==============================] - 14s 14s/step - loss: 1.5226 - val_loss: 1.0496\n",
      "Epoch 3/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_003.ckpt\\assets\n",
      "INFO:tensorflow:Assets written to: vgg_16_best.ckpt\\assets\n",
      "1/1 [==============================] - 14s 14s/step - loss: 1.2616 - val_loss: 0.6851\n",
      "Epoch 4/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_004.ckpt\\assets\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6923 - val_loss: 0.7016\n",
      "Epoch 5/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_005.ckpt\\assets\n",
      "INFO:tensorflow:Assets written to: vgg_16_best.ckpt\\assets\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7058 - val_loss: 0.6780\n",
      "Epoch 6/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_006.ckpt\\assets\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6900 - val_loss: 0.7231\n",
      "Epoch 7/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_007.ckpt\\assets\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.7182 - val_loss: 0.6821\n",
      "Epoch 8/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_008.ckpt\\assets\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.6844 - val_loss: 0.6964\n",
      "Epoch 9/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_009.ckpt\\assets\n",
      "INFO:tensorflow:Assets written to: vgg_16_best.ckpt\\assets\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.7109 - val_loss: 0.6324\n",
      "Epoch 10/10\n",
      "INFO:tensorflow:Assets written to: vgg_16_ckpts_010.ckpt\\assets\n",
      "INFO:tensorflow:Assets written to: vgg_16_best.ckpt\\assets\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6468 - val_loss: 0.6214\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(CKPT_DIR)\n",
    "bm = tf.keras.callbacks.ModelCheckpoint(BEST_DIR, save_best_only=True)\n",
    "hst = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=1,\n",
    "    epochs=10,\n",
    "    callbacks=[es, mc, bm],\n",
    "    validation_data=valid_gen,\n",
    "    validation_steps=1,\n",
    "    max_queue_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data from the python generators\n",
    "\n",
    "Since the keras utilities create generators, they should be called to create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:42:30.170754Z",
     "start_time": "2019-03-13T13:42:13.039675Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = [next(test_gen) for _ in range(test_gen.n)]\n",
    "test_data = list(zip(*test_data))\n",
    "test_X, test_y = test_data\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_y = np.concatenate(test_y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the result using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:44:05.839533Z",
     "start_time": "2019-03-13T13:44:01.634487Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(BEST_DIR)\n",
    "test_y_pred = best_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9917355371900827"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7727272727272727"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y > 0.5, test_y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      1.00      0.81        11\n",
      "        True       1.00      0.55      0.71        11\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.84      0.77      0.76        22\n",
      "weighted avg       0.84      0.77      0.76        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y > 0.5, test_y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y > 0.5, test_y_pred > 0.5)[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEJCAYAAABfZHZuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAUmElEQVR4nO3dfXBV9Z3H8c/NhmDgcgVrHkQtVBHZImWxWI0CalEoT0IisxK2S5SVB9tEwSpgfMiuAkXtNLM241RX0OgiIpUEtUJlRBGaWIp1jEJpRUggEpMIxVsggeSes390e3tCgNx7w805v+T9mjkznkNyzhfH+czX7/2d3/XZtm0LAGCEBLcLAABEjtAGAIMQ2gBgEEIbAAxCaAOAQQhtADBIotsFRKLpqz1ulwCPSe470u0S4FHNJ75o1+9Hkzfdzr+kXc+KhRGhDQAdxgq5XcEZEdoA4GRbbldwRoQ2ADhZhDYAGMOm0wYAg4Sa3a7gjAhtAHDig0gAMAjjEQAwCB9EAoA5+CASAExCpw0ABgk1uV3BGRHaAODEeAQADMJ4BAAMQqcNAAbxeKfNlyAAgINtNUV8ROvIkSOaOHGiqqurJUllZWWaNGmSxowZo8LCwojuQWgDgJNlRX5E4eOPP1Z2drYqKyslSY2NjcrPz9fTTz+tt956S59++qk2b97c5n0IbQBwsq3Ijyi8+uqrKigoUGpqqiSpoqJC/fr108UXX6zExERNmjRJGzZsaPM+zLQBwCmKDaOCwaCCwWCr64FAQIFAoMW1JUuWtDivq6tTSkpK+Dw1NVW1tbVtPpPQBgCnKDro4uJiFRUVtbqem5urvLy8M/6uZVny+Xz/eKxttzg/HUIbAJyimFXn5OQoMzOz1fWTu+xTSU9PV319ffi8vr4+PDo5E0IbAJyi+BKEU41BIjV06FDt3btXVVVVuuiii/Tmm2/q1ltvbfP3CG0AcOqgddrdu3fXsmXLlJeXp+PHj+v666/XD37wgzZ/z2fbtt0B9bVL01d73C4BHpPcd6TbJcCjmk980a7fb3j/hYh/NnnU7e16VizotAHAyeNvRBLaAODE3iMAYBA6bQAwSBSrR9xAaAOAE+MRADAI4xEAMAihDQAGYTwCAAbhg0gAMAjjEQAwCOMRADAInTYAGITQBgCDeHzjU0IbAJyaWT0CAObgg0gAMAgzbQAwCDNtADAInTYAGITQBgBz2KGQ2yWcEaENAE502gBgEJb8AYBBLFaPAIA5PD4eSXC7AJyZbdvKf+xnev7lX4WvBf96RJkz7tKnf/yzi5XBC8aPG60/fLhROz59X6+seka9evndLsl8oVDkhwsIbQ/7vHKf/uPuB7Txva3ha++XbdP0WfNUua/axcrgBeeff56e+5+f619vm63BV4zS3r1VWrok3+2yzGdZkR8uiNt45PPPP9dvfvMbffnll0pISFBqaqpGjhypIUOGxOuRnc4rr72pWyeN1QVpKeFrK3/1un5acL9+8tBSFyuDF9x88/Xavv1j7d69V5L0y2de1B+2b1Te3QR3u3h8ph2XTnvlypW69957JUlDhgzR4MGDJUkPP/ywVqxYEY9HdkoP/uRHmjDmxhbXnvn5Yg3558tdqghecvFFfbW/+kD4vLq6RueeG2BE0l62Ffnhgrh02i+++KJKS0uVnJzc4vodd9yhzMxMzZw5Mx6PBbqUhIQE2afYJyPk8ZdDPK8rdtqJiYlqPsWetI2NjerWrVs8Hgl0Ofv2f6G+fdPC5xdemK5Dh/6iY8caXKzKfLZlRXy4IS6d9ty5czVlyhRlZGQoJSVFPp9PdXV1+uCDDzR//vx4PBLocjZu3KwnH39EAwZ8S7t379Wc2f+u19942+2yzBen/1NZt26dnn32WUnSqFGjtHDhwpjuE5fQnjRpkr73ve+pvLxcdXV1sixLw4cPV15entLS0tq+AYA21dcf1J2z7tXqV55VUlI37fm8SrfPvMftsswXh/FIQ0ODlixZog0bNigQCCg7O1tlZWW69tpro75X3FaPpKWlacqUKfG6fZey5KGftLr29mvFLlQCr1m/YZPWb9jkdhmdSxRjj2AwqGAw2Op6IBBQIBAIn4dCIVmWpYaGBvXo0UPNzc3q3r17TOXxRiQAOEXRaRcXF6uoqKjV9dzcXOXl5YXP/X6/7rnnHo0bN07Jycm66qqrdOWVV8ZUHqENAE5RLOXLyclRZmZmq+vOLluSdu3apddee03vvvuuevXqpfvuu0/Lly/XnXfeGXV5hDYAOEXRaZ88BjmdrVu3KiMjQ9/4xjckSVlZWXr55ZdjCm1eYwcAB7s5FPERqUGDBqmsrEzHjh2TbdvatGlTzG+H02kDgFMcVo+MGDFCO3fuVFZWlrp166YhQ4Zo9uzZMd3LZ5/qlSqPafpqj9slwGOS+450uwR4VPOJL9r1+0fumxzxz/p/tq5dz4oFnTYAOHn8NXZCGwAcbEIbAAwSxQeMbiC0AcCJThsADEJoA4A5vL6gjtAGACc6bQAwCKENAOawm935RppIEdoA4OTtzCa0AcCJl2sAwCSENgAYhPEIAJiD8QgAGMRuJrQBwByMRwDAHFF8r68rCG0AcCK0AcAcdNoAYBC72e0KzozQBgAHOm0AMAihDQAmsX1uV3BGhDYAONBpA4BBbItOGwCMYYUIbQAwBuMRADAI4xEAMIjt7U3+CG0AcPJ6p53gdgEA4CVWyBfxEY1NmzYpKytL48aN0+LFi2Ouj9AGAAfb8kV8RGr//v0qKCjQ008/rddff107d+7U5s2bY6qP8QgAONhxeCNy48aNGj9+vNLT0yVJhYWF6t69e0z3IrQBwCGaJX/BYFDBYLDV9UAgoEAgED6vqqpSt27dNHfuXNXU1OiGG27QvHnzYqqvzfGIZVl67rnntHDhQh05ckTPPPOMQqFQTA8DAK+zbF/ER3FxsUaPHt3qKC4ubnHPUCik8vJyLV26VKtXr1ZFRYVKSkpiqq/NTvuJJ57QoUOH9Mknn0iStmzZovr6ej300EMxPRAAvCya8UhOTo4yMzNbXXd22ZJ0/vnnKyMjQ+edd54k6aabblJFRYWysrKirq/N0C4vL1dJSYmysrLk9/u1YsUKTZ48OeoHAYAJolkVcvIY5HRuvPFGLVy4UMFgUD179tSWLVs0evTomOprM7QTExOVkPCPKUpSUpISExmFA+ic4rFOe+jQobrzzjs1ffp0NTU16brrrtOtt94a073aTN+BAwdq5cqVCoVC2rNnj1544QUNGjQopocBgNdZcdpPe+rUqZo6dWq779PmB5EPPvigduzYoYMHDyo7O1tHjx5Vfn5+ux8MAF5k276IDze02Wn7/X4tXbq0I2oBANcZv/fI6V63ZPUIgM4oXuORs6XN8Ujv3r3DR8+ePbVt27aOqAsAXGFZvogPN7TZaefm5rY4nzVrlu666664FXQq7w5mho6Wdl46xO0S0El5vdOOeu2e3+9XXV1dPGoBANe59QFjpNoM7ccee0w+39/+ErZta8eOHbrkkkviXhgAuMH4TrtPnz4tzm+55RbdcsstcSsIANzk8cUjbYf2vn379MQTT3RELQDgupDl7a8ZaDO0d+3aJdu2wyMSAOjMPP5l7KcP7RMnTigpKUkpKSmaMGGChg4dqp49e4b/nHXaADojW95uUE8b2rfddptKSko0bNgwDRs2rCNrAgDXWB4fap82tO3/f5fz5HXaANCZWaZ22sePH9fOnTvD4X2ywYMHx60oAHCLseOR/fv3Ky8v75Sh7fP59M4778S1MABwQ8jU0B4wYIBKS0s7shYAcJ2xq0cAoCsyNrSHDx/ekXUAgCcYO9NmHTaArsilHVcjxngEAByMXfIHAF1RyO0C2kBoA4CD5fF9lghtAHDw+FvshDYAOBm75A8AuiJWjwCAQYx9jR0AuiI6bQAwCDNtADAIq0cAwCCMRwDAIF4fj3j7u+IBoIOFfJEfsXj88ce1aNGimOsjtAHAwYriiFZ5eblKSkraVR/jEQBwiCaMg8GggsFgq+uBQECBQKDFtcOHD6uwsFBz587Vrl27Yq6P0AYAh2hWjxQXF6uoqKjV9dzcXOXl5bW49sgjj2j+/PmqqalpV32ENgA4RLN65I6cHGVmZra6fnKXvWbNGl1wwQXKyMjQ2rVr21UfoQ0ADtGMR041BjmVt956S/X19Zo8ebK+/vprHTt2TEuXLlV+fn7U9RHaAOAQjy9BeP7558P/vHbtWm3bti2mwJYIbQBogZdrAMAg8X65JisrS1lZWTH/PqENAA7sPQIABrE8HtuENgA48G3sAGAQr28YRWgDgAOrRwDAIMy0AcAg3o5sQhsAWmCmDQAGCXm81ya0AcCBThsADMIHkQBgEG9HNqENAC0wHgEAg/BBJM6Kgf/5Q6VNukZNh49Iko59XqOK2f/tclVwW9Jl/ZX60I+U4O8hWZZqC57S8Z273S7LaMy0cVb0vmqgKuY8pa+3/9ntUuARvnO666LlS1X7UKGOvv979fz+NbrgyYWqnDDL7dKM5u3IJrSN4EtKVK8r+utbuZOU3D9Nxz6v0Z8eeVGNXxx0uzS4qMd1V6ppX42Ovv97SdLRTR+oqbrW5arM5/VOO8HtAtC2c9L76NDWHdq9bLXKb1igrz/8TP9SfJ/bZcFlSf0vVPNXh5S2eL6+ueYpXbjip/Il/pPbZRnPiuJwQ1w67QMHDpzxz/v27RuPx3ZaDfvq9dG/PR4+r3z6TV1yb5aSv5mihn31LlYGN/kSE9Vz1FWqvn2hGiv+pJ7fv0YX/vJR7R2dI7upye3yjGV7vNOOS2jPmTNHlZWVSk1NlW23/Bfg8/n0zjvvxOOxnZb/299Ur2/3U82vtvzjos8nq8nr27UjnprrDurEnv1qrPiTpL+NR/TYPHW7OF0n9ux3uTpzdcnVI6tWrdL06dNVUFCg7373u/F4RNdiWRq0JEeHt+1Sw756XXz7zfrrzn06XnPI7crgoqNbtitlwWx1//YAHd+5W8nDr5Bsqan6S7dLM1qXXKft9/u1ePFirVmzhtA+C47sqtau/Bc07KUFUkKCjtcc1Cdzn3K7LLgs9NVfdCDvv5T6SK4Sepwj+0STDtz9mOwTjEbaw7K93Wn77JPnFx70dto0t0uAx/Q/77DbJcCjBv5xQ7t+/4f9siL+2f+tWtuuZ8WCJX8A4OD1JX+ENgA4dMnVIwBgqmZCGwDMQacNAAbpkkv+AMBUXl9QR2gDgAOrRwDAIPF6jb2oqEjr16+XJF1//fVasGBBTPdhlz8AcLBkR3xEqqysTFu3blVJSYlKS0u1Y8cObdy4Mab66LQBwCEeM+2UlBQtWrRISUlJkqRLL720zd1QT4fQBgCHaFaPBINBBYPBVtcDgYACgUD4/LLLLgv/c2VlpdavX69Vq1bFVB+hDQAO0azTLi4uVlFRUavrubm5ysvLa3X9s88+05w5c7RgwQL1798/pvoIbQBwiGZWnZOTo8zMzFbXnV3233344Ye6++67lZ+frwkTJsRcH6ENAA4hO/IBycljkNOpqanRj3/8YxUWFiojI6M95RHaAOAUj9fYly9fruPHj2vZsmXha9OmTVN2dnbU92I/bRiJ/bRxOu3dT3vUhaMj/tn3v+j4r06k0wYAB693sYQ2ADjwGjsAGITQBgCDRLN6xA2ENgA48CUIAGAQry+oI7QBwIGZNgAYhE4bAAwS8vi3RBLaAOBg0WkDgDlYPQIABqHTBgCD0GkDgEHotAHAILzGDgAGYTwCAAax6bQBwBy8xg4ABuE1dgAwCJ02ABgkZDHTBgBjsHoEAAzCTBsADMJMGwAMQqcNAAbhg0gAMAjjEQAwCOMRADAIW7MCgEFYpw0ABvF6p53gdgEA4CWWbUV8ROONN97Q+PHjNWbMGK1cuTLm+ui0AcAhHh9E1tbWqrCwUGvXrlVSUpKmTZumq6++WgMGDIj6XoQ2ADhEE9rBYFDBYLDV9UAgoEAgED4vKyvTNddco969e0uSxo4dqw0bNig3Nzfq+owI7TG1r7hdAoAuounEFxH/7C9+8QsVFRW1up6bm6u8vLzweV1dnVJSUsLnqampqqioiKk+I0IbALwoJydHmZmZra47u2xJsixLPp8vfG7bdovzaBDaABCjk8cgp5Oenq7t27eHz+vr65WamhrTM1k9AgBxdu2116q8vFyHDh1SQ0OD3n77bY0aNSqme9FpA0CcpaWlaf78+ZoxY4aampo0depUfec734npXj7b6y/aAwDCGI8AgEEIbQAwCKENAAYhtAHAIIS2Ic7WZjPofI4cOaKJEyequrra7VLQAQhtA/x9s5mXX35ZpaWlWr16tXbv3u12WfCAjz/+WNnZ2aqsrHS7FHQQQtsAzs1mevToEd5sBnj11VdVUFAQ89t1MA8v1xjgbG42g85lyZIlbpeADkanbYCzudkMALMR2gZIT09XfX19+Lw9m80AMBuhbYCzudkMALMx0zbA2dxsBoDZ2DAKAAzCeAQADEJoA4BBCG0AMAihDQAGIbQBwCAs+YNnVFdX6+abb9bAgQPD12zb1owZMzR16tSY7ztnzhyNHTtWWVlZZ6NMwFWENjzlnHPO0bp168LntbW1mjhxoq644goNGjTIxcoAbyC04WlpaWnq16+ffvvb3+rRRx9VQ0OD/H6/XnrpJa1Zs0arVq2SZVnq3bu3Hn74YV166aWqra3VokWLVFdXp759++rgwYNu/zWAs4bQhqd99NFH2rdvnxobG7V7925t2rRJfr9f27ZtU2lpqVauXKnk5GRt3bpVubm5Wr9+vR599FENHTpU8+bNU1VVlaZMmeL2XwM4awhteEpjY6MmT54sSQqFQurTp4+efPJJHTx4UJdffrn8fr8k6b333lNVVZWmTZsW/t1gMKjDhw+rrKxMCxculCT169dPV199dcf/RYA4IbThKSfPtP9u7dq16tGjR/jcsixNnjxZ999/f/i8rq5O5557rnw+n5y7MyQm8p85Og+W/MFII0aM0K9//WvV1dVJklatWqWcnBxJ0siRI7V69WpJ0oEDB/S73/3OtTqBs40WBEYaMWKEZs2apZkzZ8rn88nv96uoqEg+n08FBQV64IEHNG7cOKWnp7PqBJ0Ku/wBgEEYjwCAQQhtADAIoQ0ABiG0AcAghDYAGITQBgCDENoAYBBCGwAM8n9Fm/DurPQy2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(test_y > 0.5, test_y_pred > 0.5), annot=True)\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Pred')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

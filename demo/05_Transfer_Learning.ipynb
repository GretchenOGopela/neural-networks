{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "This notebook shows how to apply transfer learning on image datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:34:47.416060Z",
     "start_time": "2019-03-13T13:34:45.812050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.backend import tensorflow_backend as Ktf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from keras.activations import relu, sigmoid\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the data location and the place to save the model\n",
    "\n",
    "Unfortunately the data used here is a private data. However it can be replaced by any healthy/unhealthy classification problem as long as the folder structure is followed.\n",
    "\n",
    "*   training\n",
    "    *   healthy\n",
    "    *   unhealthy    \n",
    "*   test    \n",
    "    *   healthy\n",
    "    *   unhealthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:42:00.019264Z",
     "start_time": "2019-03-13T13:42:00.016388Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '~/datasets/plant/train/'\n",
    "TEST_DIR = '~/datasets/plant/test'\n",
    "CKPT_DIR='vgg_16_ckpts_{epoch:03d}.hdf5'\n",
    "BEST_DIR='vgg_16_best.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the images and add augmentations\n",
    "\n",
    "The training/validation set has multiple random data transformations while the training set is just scaled for the sake of normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:42:01.042333Z",
     "start_time": "2019-03-13T13:42:00.713058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 369 images belonging to 2 classes.\n",
      "Found 91 images belonging to 2 classes.\n",
      "Found 115 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_idg = ImageDataGenerator(rotation_range=360,\n",
    "                               zoom_range=0.5,\n",
    "                               fill_mode='reflect',\n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True,\n",
    "                               validation_split=0.2,\n",
    "                               rescale=1.0/255)\n",
    "test_idg = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "class_mode = 'binary'\n",
    "classes = {\n",
    "    'healthy': 0,\n",
    "    'unhealthy': 1,\n",
    "}\n",
    "\n",
    "train_gen = train_idg.flow_from_directory(TRAIN_DIR, (224, 224),\n",
    "                                          seed=0,\n",
    "                                          batch_size=128,\n",
    "                                          subset='training',\n",
    "                                          class_mode=class_mode,\n",
    "                                          classes=classes)\n",
    "\n",
    "valid_gen = train_idg.flow_from_directory(TRAIN_DIR, (224, 224),\n",
    "                                          seed=0,\n",
    "                                          batch_size=128,\n",
    "                                          subset='validation',\n",
    "                                          class_mode=class_mode,    \n",
    "                                          classes=classes)\n",
    "\n",
    "test_gen = test_idg.flow_from_directory(TEST_DIR, (224, 224),\n",
    "                                        class_mode=class_mode,\n",
    "                                        classes=classes,\n",
    "                                        shuffle=False,\n",
    "                                        batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a base model and add additional layers\n",
    "\n",
    "Load the keras VGG model without the last/top layers and add the needed layers to solve the classification problem. Also some of the initial layers of the VGG model are set to be not trainable since only fine tuning is done to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-10T13:32:54.349Z"
    }
   },
   "outputs": [],
   "source": [
    "img_input = Input((224, 224, 3))\n",
    "base_model = VGG16(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=img_input)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=relu)(x)\n",
    "predictions = Dense(1, activation=sigmoid)(x)\n",
    "\n",
    "model = Model(inputs=img_input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer=SGD(0.01, decay=1e-9), loss=binary_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Keras model\n",
    "\n",
    "Different callbacks are also added to improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-10T13:32:54.357Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 2792s 28s/step - loss: 0.4842 - val_loss: 0.4015\n",
      "Epoch 2/10\n",
      "  9/100 [=>............................] - ETA: 27:25 - loss: 0.4536"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=20)\n",
    "mc = ModelCheckpoint(CKPT_DIR)\n",
    "bm = ModelCheckpoint(BEST_DIR, save_best_only=True)\n",
    "hst = model.fit_generator(train_gen,\n",
    "                          steps_per_epoch=20,\n",
    "                          epochs=50,\n",
    "                          callbacks=[es, mc, bm],\n",
    "                          validation_data=valid_gen,\n",
    "                          validation_steps=20,\n",
    "                          max_queue_size=40,\n",
    "                          use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data from the python generators\n",
    "\n",
    "Since the keras utilities create generators, they should be called to create the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:42:30.170754Z",
     "start_time": "2019-03-13T13:42:13.039675Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = [next(test_gen) for _ in range(test_gen.n)]\n",
    "test_data = list(zip(*test_data))\n",
    "test_X, test_y = test_data\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_y = np.concatenate(test_y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the result using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T13:44:05.839533Z",
     "start_time": "2019-03-13T13:44:01.634487Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = load_model(BEST_DIR)\n",
    "test_y_pred = best_model.predict(test_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
